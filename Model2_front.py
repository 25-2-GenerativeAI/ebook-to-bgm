import os
from dotenv import load_dotenv
import pandas as pd
from collections import defaultdict
from transformers import pipeline
from openai import OpenAI
import torch
from diffusers import AudioLDM2Pipeline
import soundfile as sf
import torch.nn as nn

# .env íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
print("API KEY:", api_key)

# -------------------------------
# Step 1. í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
# -------------------------------

def load_text(file_path: str) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"{file_path} not found.")
    with open(file_path, "r", encoding="utf-8") as f:
        text = f.read()
    return text

def split_into_paragraphs(text: str) -> list[str]:
    """ë¹ˆ ì¤„(\\n\\n)ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ ë¶„ë¦¬"""
    paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
    return paragraphs

def sliding_window(paragraphs: list[str], window_size: int = 3, stride: int = 1) -> list[list[str]]:
    """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±"""
    windows = []
    for i in range(0, len(paragraphs) - window_size + 1, stride):
        windows.append(paragraphs[i:i+window_size])
    return windows

# -------------------------------
# Step 2. ê°ì • ë¶„ë¥˜ê¸° (RoBERTa)
# -------------------------------

emotion_model_name = "j-hartmann/emotion-english-distilroberta-base"

emotion_classifier = pipeline(
    "text-classification",
    model=emotion_model_name,
    top_k=1,
)

def detect_emotion(text: str) -> str:
    """BERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜"""
    result = emotion_classifier(text[:512])  
    if isinstance(result[0], list):  
        return result[0][0]["label"]
    else:
        return result[0]["label"]

# -------------------------------
# Step 3. LSN ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------

def load_sensorimotor_db(path: str) -> dict:
    """
    Lancaster Sensorimotor Norms ë¶ˆëŸ¬ì˜¤ê¸°
    CSV/XLSX ëª¨ë‘ ì§€ì›
    ë°˜í™˜: {ë‹¨ì–´: {ê°ê°: ì ìˆ˜}}
    """
    if path.endswith(".csv"):
        df = pd.read_csv(path)
    else:
        df = pd.read_excel(path)

    # ì»¬ëŸ¼ ì´ë¦„ ë§¤í•‘ (LSN â†’ ìš°ë¦¬ ì½”ë“œ)
    sense_map = {
        "Auditory.mean": "hearing",
        "Gustatory.mean": "taste",
        "Haptic.mean": "touch",
        "Interoceptive.mean": "interoception",
        "Olfactory.mean": "smell",
        "Visual.mean": "vision",
    }

    db = {}
    for _, row in df.iterrows():
        word = str(row["Word"]).lower()
        db[word] = {
            sense_map[col]: float(row[col])
            for col in sense_map if col in row and not pd.isna(row[col])
        }
    return db

# -------------------------------
# Step 4. ê°ê° íƒœê¹… (LSN ê¸°ë°˜)
# -------------------------------

def detect_senses(text: str, db: dict, threshold: float = 3.0) -> list[str]:
    """
    LSN ê¸°ë°˜ sensory íƒœê¹…
    threshold ì´ìƒ í‰ê· ê°’ì¸ ê°ê°ì„ ë°˜í™˜
    """
    tokens = text.lower().split()  # ê³µë°± ê¸°ì¤€ ë‹¨ìˆœ í† í°í™”
    scores = defaultdict(float)
    counts = defaultdict(int)

    for tok in tokens:
        if tok in db:
            for sense, score in db[tok].items():
                scores[sense] += score
                counts[sense] += 1

    senses = []
    for sense, total_score in scores.items():
        avg_score = total_score / counts[sense]
        if avg_score >= threshold:
            senses.append(sense)
    return senses

# -------------------------------
# Step 5. ìœˆë„ìš° íƒœê¹…
# -------------------------------

import re
from collections import Counter

def tag_window(window: list[str], db: dict) -> dict:
    """ìœˆë„ìš°(ì—¬ëŸ¬ ë¬¸ë‹¨)ì— ëŒ€í•´ ê°ì •+ê°ê° íƒœê¹… (ê°œì„  ë²„ì „)"""
    combined_text = " ".join(window)

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    sentences = re.split(r"[.!?]\s+", combined_text)
    emotions = []
    for sent in sentences:
        sent = sent.strip()
        if sent:
            emotions.append(detect_emotion(sent))

    # ë‹¤ìˆ˜ê²° (ë¬¸ì¥ì´ ì—†ìœ¼ë©´ neutral)
    if emotions:
        emotion = Counter(emotions).most_common(1)[0][0]
    else:
        emotion = "neutral"

    # ê°ê° íƒœê¹… (êµ¬ë‘ì  ì œê±° + threshold ë‚®ì¶¤)
    cleaned_text = re.sub(r"[^a-zA-Z\s]", "", combined_text.lower())
    senses = detect_senses(cleaned_text, db, threshold=2.5)

    return {
        "text": combined_text,
        "emotion": emotion,
        "senses": senses
    }


import json

if __name__ == "__main__":
    # 1. í…ìŠ¤íŠ¸ â†’ ë¬¸ë‹¨/ìœˆë„ìš°
    text = load_text("data.txt")
    paragraphs = split_into_paragraphs(text)
    windows = sliding_window(paragraphs, window_size=3, stride=1)

    # 2. LSN DB ë¡œë“œ
    lsn_db_path = "LSN.csv"   # ğŸ‘‰ ì‹¤ì œ ê²½ë¡œ ë§ê²Œ ìˆ˜ì •
    lsn_db = load_sensorimotor_db(lsn_db_path)

    # 3. ê° ìœˆë„ìš° íƒœê¹…
    tagged = []
    for i, window in enumerate(windows):
        tags = tag_window(window, lsn_db)
        tagged.append(tags)

    # 4. JSONìœ¼ë¡œ ì €ì¥
    with open("windows.json", "w", encoding="utf-8") as f:
        json.dump(tagged, f, ensure_ascii=False, indent=2)

    print(f"âœ… {len(tagged)} windows saved to windows.json")
