import os
import json
import torch
import soundfile as sf
from diffusers import AudioLDMPipeline  # âœ… v1 íŒŒì´í”„ë¼ì¸
import numpy as np

# -------------------------------
# ì˜¤ë””ì˜¤ ìƒì„± í•¨ìˆ˜
# -------------------------------
def generate_audio_from_prompt(pipe, prompt: str, output_path="output.wav", duration=10, steps=50):
    audio = pipe(
        prompt=prompt,
        num_inference_steps=steps,
        audio_length_in_s=duration,
        guidance_scale=2.0,
        generator=torch.manual_seed(0),
    ).audios[0]

    # AudioLDM v1 ê¸°ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 16kHz
    sr = pipe.vae.config.get("sampling_rate", 16000)

    # numpy ë³€í™˜ ë³´ì •
    if isinstance(audio, torch.Tensor):
        audio = audio.detach().cpu().numpy()
    audio = audio.astype(np.float32)

    sf.write(output_path, audio, sr)
    print(f"âœ… Saved audio at {output_path} ({sr}Hz)")

# -------------------------------
# ì‹¤í–‰ë¶€
# -------------------------------
def main(input_json="prompts.json", out_dir="outputs"):
    if not os.path.exists(input_json):
        raise FileNotFoundError(f"{input_json} not found.")

    with open(input_json, "r", encoding="utf-8") as f:
        prompts = json.load(f)

    # âœ… íŒŒì´í”„ë¼ì¸ í•œ ë²ˆë§Œ ë¡œë“œ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    pipe = AudioLDMPipeline.from_pretrained(
        "cvssp/audioldm-large",   # âš¡ v1 ëª¨ë¸ (ì•ˆì •ì )
        torch_dtype=torch.float16,
    ).to(device)

    # âœ… ì˜¤ë””ì˜¤ ì €ì¥ í´ë” ìƒì„±
    audio_dir = os.path.join(out_dir, "audio")
    os.makedirs(audio_dir, exist_ok=True)

    # prompts.jsonì´ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¼ê³  ê°€ì •
    for idx, prompt in enumerate(prompts, start=1):
        print(f"\nğŸ§ Generating audio for Scene {idx}...")
        output_file = os.path.join(audio_dir, f"scene_{idx:03}.wav")
        generate_audio_from_prompt(pipe, prompt, output_path=output_file, duration=10, steps=50)

    print(f"\nâœ… All audios generated successfully! Saved in '{audio_dir}'")

if __name__ == "__main__":
    main()
